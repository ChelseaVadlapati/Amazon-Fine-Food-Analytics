{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519104e3",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937f2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure output dirs exist\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "os.makedirs(\"../Dashboards\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5542f0d",
   "metadata": {},
   "source": [
    "Load data and create target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4206aa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score  Sentiment\n",
       "0      5          1\n",
       "1      1          0\n",
       "2      4          1\n",
       "3      2          0\n",
       "4      5          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned reviews\n",
    "df = pd.read_csv(\"../Data Processed/Cleaned Reviews.csv\")\n",
    "\n",
    "# Drop neutral reviews\n",
    "df = df[df[\"Score\"] != 3]\n",
    "\n",
    "# Binary sentiment: 1 = positive (4–5), 0 = negative (1–2)\n",
    "df[\"Sentiment\"] = df[\"Score\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "X = df[\"Text\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "df[[\"Score\", \"Sentiment\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58d966",
   "metadata": {},
   "source": [
    "TF-IDF with unigrams + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3bd6897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((420651, 30000), (105163, 30000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 2)  # unigrams + bigrams\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e64aa4",
   "metadata": {},
   "source": [
    "Model comparison (LogReg, NB, LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f87e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseavadlapati/amazon-fine-food-clean/.venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (neg)</th>\n",
       "      <th>Recall (neg)</th>\n",
       "      <th>F1 (neg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.950058</td>\n",
       "      <td>0.869640</td>\n",
       "      <td>0.799781</td>\n",
       "      <td>0.833249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.883439</td>\n",
       "      <td>0.728957</td>\n",
       "      <td>0.798798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.910339</td>\n",
       "      <td>0.894594</td>\n",
       "      <td>0.482111</td>\n",
       "      <td>0.626559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision (neg)  Recall (neg)  F1 (neg)\n",
       "2           LinearSVC  0.950058         0.869640      0.799781  0.833249\n",
       "0  LogisticRegression  0.942708         0.883439      0.728957  0.798798\n",
       "1       MultinomialNB  0.910339         0.894594      0.482111  0.626559"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LinearSVC\": LinearSVC()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Focus on negative class (0) for precision/recall/F1\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        average=\"binary\",\n",
    "        pos_label=0\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision (neg)\": precision,\n",
    "        \"Recall (neg)\": recall,\n",
    "        \"F1 (neg)\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(\"F1 (neg)\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f83b01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (neg)</th>\n",
       "      <th>Recall (neg)</th>\n",
       "      <th>F1 (neg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.883439</td>\n",
       "      <td>0.728957</td>\n",
       "      <td>0.798798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.910339</td>\n",
       "      <td>0.894594</td>\n",
       "      <td>0.482111</td>\n",
       "      <td>0.626559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.950058</td>\n",
       "      <td>0.869640</td>\n",
       "      <td>0.799781</td>\n",
       "      <td>0.833249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision (neg)  Recall (neg)  F1 (neg)\n",
       "0  LogisticRegression  0.942708         0.883439      0.728957  0.798798\n",
       "1       MultinomialNB  0.910339         0.894594      0.482111  0.626559\n",
       "2           LinearSVC  0.950058         0.869640      0.799781  0.833249"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv(\"../Models/Model Comparison Results.csv\", index=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2eb790",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for LinearSVC (optimize F1 on negative class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed553216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Best params: {'C': 1, 'loss': 'squared_hinge'}\n",
      "Best CV F1 (neg): 0.7358271088978684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# smaller sample for tuning\n",
    "X_tune, _, y_tune, _ = train_test_split(\n",
    "    X_train, y_train,\n",
    "    train_size=50000,   # e.g. 50k samples\n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "neg_f1_scorer = make_scorer(f1_score, pos_label=0)\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"loss\": [\"squared_hinge\"]  # fix this to reduce combos\n",
    "}\n",
    "\n",
    "svc = LinearSVC(max_iter=5000, dual=False)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    svc,\n",
    "    param_grid,\n",
    "    scoring=neg_f1_scorer,\n",
    "    cv=2,        # lighter CV\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_tune, y_tune)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV F1 (neg):\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d4576",
   "metadata": {},
   "source": [
    "Evaluate tuned LinearSVC on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d534599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9500584806443331\n",
      "\n",
      "Negative class metrics:\n",
      "Precision (neg): 0.8696891363425465\n",
      "Recall (neg): 0.799719631864448\n",
      "F1 (neg): 0.8332380770940496\n",
      "\n",
      "Classification report (all classes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83     16407\n",
      "           1       0.96      0.98      0.97     88756\n",
      "\n",
      "    accuracy                           0.95    105163\n",
      "   macro avg       0.92      0.89      0.90    105163\n",
      "weighted avg       0.95      0.95      0.95    105163\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[13121  3286]\n",
      " [ 1966 86790]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train best model on full training data\n",
    "best_svc = LinearSVC(\n",
    "    C=grid.best_params_[\"C\"],\n",
    "    loss=grid.best_params_[\"loss\"],\n",
    "    max_iter=5000,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "\n",
    "print(\"\\nNegative class metrics:\")\n",
    "precision_neg = precision_score(y_test, y_pred_svc, pos_label=0)\n",
    "recall_neg = recall_score(y_test, y_pred_svc, pos_label=0)\n",
    "f1_neg = f1_score(y_test, y_pred_svc, pos_label=0)\n",
    "print(\"Precision (neg):\", precision_neg)\n",
    "print(\"Recall (neg):\", recall_neg)\n",
    "print(\"F1 (neg):\", f1_neg)\n",
    "\n",
    "print(\"\\nClassification report (all classes):\")\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36172d11",
   "metadata": {},
   "source": [
    "Train Logistic Regression for explainability (coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84cdbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = log_reg.coef_[0]  # coef > 0 -> pushes toward class 1 (positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca8a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            word       coef\n",
       " 0          worst -12.243729\n",
       " 1  disappointing -10.907983\n",
       " 2       terrible  -9.969264\n",
       " 3   disappointed  -9.531933\n",
       " 4          awful  -9.126645,\n",
       "         word      coef\n",
       " 0     easier  4.443439\n",
       " 1     unique  4.512170\n",
       " 2  complaint  4.568517\n",
       " 3  beautiful  4.660276\n",
       " 4   terrific  4.855010)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strong negative indicators: most negative coefficients (toward class 0)\n",
    "top_neg_idx = np.argsort(coefs)[:50]\n",
    "top_pos_idx = np.argsort(coefs)[-50:]\n",
    "\n",
    "top_neg_words = [(feature_names[i], coefs[i]) for i in top_neg_idx]\n",
    "top_pos_words = [(feature_names[i], coefs[i]) for i in top_pos_idx]\n",
    "\n",
    "# Turn into DataFrames for export\n",
    "neg_words_df = pd.DataFrame(top_neg_words, columns=[\"word\", \"coef\"])\n",
    "pos_words_df = pd.DataFrame(top_pos_words, columns=[\"word\", \"coef\"])\n",
    "\n",
    "neg_words_df.to_csv(\"../Dashboards/Top negative words model coeffs.csv\", index=False)\n",
    "pos_words_df.to_csv(\"../Dashboards/Top positive words model coeffs.csv\", index=False)\n",
    "\n",
    "neg_words_df.head(), pos_words_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc73ae",
   "metadata": {},
   "source": [
    "Frequency-based complaint keywords (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931da637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br</td>\n",
       "      <td>104606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>44561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product</td>\n",
       "      <td>35007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taste</td>\n",
       "      <td>32120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just</td>\n",
       "      <td>28111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>food</td>\n",
       "      <td>22825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coffee</td>\n",
       "      <td>22675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>21665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flavor</td>\n",
       "      <td>20543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amazon</td>\n",
       "      <td>16708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>don</td>\n",
       "      <td>16660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tea</td>\n",
       "      <td>16332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>buy</td>\n",
       "      <td>15040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>really</td>\n",
       "      <td>14489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tried</td>\n",
       "      <td>12048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dog</td>\n",
       "      <td>11962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>box</td>\n",
       "      <td>11899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>11700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bought</td>\n",
       "      <td>11247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>did</td>\n",
       "      <td>11136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word   count\n",
       "0        br  104606\n",
       "1      like   44561\n",
       "2   product   35007\n",
       "3     taste   32120\n",
       "4      just   28111\n",
       "5      food   22825\n",
       "6    coffee   22675\n",
       "7      good   21665\n",
       "8    flavor   20543\n",
       "9    amazon   16708\n",
       "10      don   16660\n",
       "11      tea   16332\n",
       "12      buy   15040\n",
       "13   really   14489\n",
       "14    tried   12048\n",
       "15      dog   11962\n",
       "16      box   11899\n",
       "17     time   11700\n",
       "18   bought   11247\n",
       "19      did   11136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df = df[df[\"Sentiment\"] == 0]\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "neg_matrix = cv.fit_transform(neg_df[\"Text\"])\n",
    "\n",
    "sum_words = neg_matrix.sum(axis=0)\n",
    "word_freq = [\n",
    "    (word, int(sum_words[0, idx]))\n",
    "    for word, idx in cv.vocabulary_.items()\n",
    "]\n",
    "\n",
    "sorted_words = sorted(word_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "complaint_words_df = pd.DataFrame(sorted_words, columns=[\"word\", \"count\"])\n",
    "complaint_words_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6938d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_words_df.to_csv(\"../Dashboards/Top negative words frequency.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704118d",
   "metadata": {},
   "source": [
    "Save best model + vectorizer for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196a03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model and TF-IDF vectorizer.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_svc, \"../Models/best_sentiment_model.pkl\")\n",
    "joblib.dump(tfidf, \"../Models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Saved best model and TF-IDF vectorizer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7d52e",
   "metadata": {},
   "source": [
    "Quick sanity check with a custom review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4cffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product was terrible, completely stale and I want a refund.\n",
      "Predicted sentiment: Negative\n",
      "------------------------------------------------------------\n",
      "Review: Absolutely loved it! Fresh, tasty and arrived on time.\n",
      "Predicted sentiment: Positive\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_reviews = [\n",
    "    \"This product was terrible, completely stale and I want a refund.\",\n",
    "    \"Absolutely loved it! Fresh, tasty and arrived on time.\",\n",
    "]\n",
    "\n",
    "X_sample = tfidf.transform(sample_reviews)\n",
    "preds = best_svc.predict(X_sample)\n",
    "\n",
    "for text, label in zip(sample_reviews, preds):\n",
    "    print(\"Review:\", text)\n",
    "    print(\"Predicted sentiment:\", \"Positive\" if label == 1 else \"Negative\")\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
